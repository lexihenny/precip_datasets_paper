{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b03ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.stats as st\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import os,errno\n",
    "import sys\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER,LATITUDE_FORMATTER\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.feature as cfeature\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import time\n",
    "import urllib.request\n",
    "import metpy.calc as mpcalc\n",
    "import salem\n",
    "import scipy.optimize as opt\n",
    "import warnings\n",
    "import geopy.distance\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "dir_data='/Users/ahenny/'\n",
    "dir1='/Volumes/LaCie/'\n",
    "dir2='/Volumes/Extreme Pro/'\n",
    "dir3='/Volumes/My Passport/day/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f72cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yrs=np.arange(2001,2021,1)\n",
    "\n",
    "for i in range(len(yrs)):\n",
    "    year=yrs[i]\n",
    "    print(year)\n",
    "    ds=xr.open_dataset(dir_data+'holding/'+'gpcp3_precip_'+str(year)+'.nc')\n",
    "    precip=ds['precip']\n",
    "    \n",
    "    defined1=xr.ones_like(precip).sum(dim='time')\n",
    "    defined=xr.ones_like(precip).where(precip.round(2)>=0).sum(dim='time')\n",
    "    \n",
    "    print(defined.mean().values.tolist())\n",
    "    \n",
    "    if i==0:\n",
    "        max_concat=defined1\n",
    "        present_concat=defined\n",
    "    else:\n",
    "        max_concat=xr.concat([max_concat,defined1],dim='time')\n",
    "        present_concat=xr.concat([present_concat,defined],dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec17ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_all=max_concat.sum(dim='time')\n",
    "present_all=present_concat.sum(dim='time')\n",
    "ratio_all=present_all/max_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e809b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yrs=np.arange(2001,2021,1)\n",
    "\n",
    "ds=xr.open_dataset(dir_data+'gpcp3_threshold_final_98_all.nc')\n",
    "#ds=xr.open_dataset(dir_data+'gpcp3_threshold_r99p.nc')\n",
    "lats_sel=[x for x in ds.lat.values if -60<=x<=70]\n",
    "threshold=ds['threshold'].sel(lat=lats_sel)\n",
    "ratio_all=ratio_all.sel(lat=lats_sel)\n",
    "\n",
    "if 1==1:\n",
    "    total_list_land=[]\n",
    "    freq_list_land=[]\n",
    "    intensity_list_land=[]\n",
    "    \n",
    "    total_list_ocean=[]\n",
    "    freq_list_ocean=[]\n",
    "    intensity_list_ocean=[]\n",
    "    \n",
    "    total_ocean_monthly=np.zeros((12,len(yrs)))\n",
    "    freq_ocean_monthly=np.zeros((12,len(yrs)))\n",
    "    intensity_ocean_monthly=np.zeros((12,len(yrs)))\n",
    "    \n",
    "    total_land_monthly=np.zeros((12,len(yrs)))\n",
    "    freq_land_monthly=np.zeros((12,len(yrs)))\n",
    "    intensity_land_monthly=np.zeros((12,len(yrs)))\n",
    "\n",
    "for i in range(len(yrs)):\n",
    "    year=yrs[i]\n",
    "    print(year)\n",
    "    factor=1.\n",
    "        \n",
    "    ds=xr.open_dataset(dir_data+'holding/'+'gpcp3_precip_'+str(year)+'.nc')\n",
    "    precip=ds['precip'].sel(lat=lats_sel)\n",
    "    weights=np.cos(np.deg2rad(precip.lat))\n",
    "\n",
    "    if i==0:#land mask option\n",
    "        ds=xr.open_dataset('/Users/ahenny/Downloads/data.nc')\n",
    "        t2m=ds['t2m'][0,:,:]\n",
    "        land_mask=t2m/t2m\n",
    "        land_mask=land_mask.fillna(0)\n",
    "        \n",
    "        lon_east=[x for x in land_mask.longitude.values if x>=180.]\n",
    "        lon_west=[x for x in land_mask.longitude.values if x<180.]\n",
    "        l_east=land_mask.sel(longitude=lon_east)\n",
    "        l_west=land_mask.sel(longitude=lon_west)\n",
    "        l_east['longitude']=[x-360. for x in lon_east]\n",
    "        land_mask=xr.concat([l_east,l_west],dim='longitude')\n",
    "        \n",
    "        dk=xr.Dataset()\n",
    "        dk['land']=(('lat','lon'),land_mask.values)\n",
    "        dk.coords['lat']=land_mask.latitude.values\n",
    "        dk.coords['lon']=land_mask.longitude.values\n",
    "        \n",
    "        land_mask=dk['land']\n",
    "        land_mask_interp=land_mask.interp_like(precip[0,:,:])\n",
    "        \n",
    "    defined1=xr.ones_like(precip).sum(dim='time').where(land_mask_interp>=0.5)\n",
    "    defined=xr.ones_like(precip).where(precip.round(2)>=0).sum(dim='time').where(land_mask_interp>=0.5)\n",
    "    ratio_land=defined/defined1\n",
    "    valid_area_land=xr.ones_like(precip).where(ratio_land>=0.9).fillna(0).where(land_mask_interp>=0.5).weighted(weights).mean().values.tolist()\n",
    "    \n",
    "    defined1=xr.ones_like(precip).sum(dim='time').where(land_mask_interp<0.5)\n",
    "    defined=xr.ones_like(precip).where(precip.round(2)>=0).sum(dim='time').where(land_mask_interp<0.5)\n",
    "    ratio_ocean=defined/defined1\n",
    "    valid_area_ocean=xr.ones_like(precip).where(ratio_ocean>=0.9).fillna(0).where(land_mask_interp<0.5).weighted(weights).mean().values.tolist()\n",
    "    \n",
    "    print((valid_area_land,valid_area_ocean))\n",
    "\n",
    "    if 1==1:\n",
    "        threshold_new=xr.zeros_like(precip)\n",
    "        for k in range(threshold_new.time.size):\n",
    "            date=pd.to_datetime(threshold_new.time.values[k])\n",
    "            if date.month==2 and date.day==29:\n",
    "                threshold_new1=threshold.sel(time=dt.datetime(2001,2,28))\n",
    "                threshold_new2=threshold.sel(time=dt.datetime(2001,3,1))\n",
    "                threshold_new3=(threshold_new1+threshold_new1)/2.\n",
    "            else:\n",
    "                threshold_new3=threshold.sel(time=dt.datetime(2001,date.month,date.day))\n",
    "\n",
    "            threshold_new[k,:,:]=threshold_new3.values\n",
    "    if 1==0:\n",
    "        threshold_new=threshold\n",
    "        \n",
    "    precip_extreme=precip.where(precip>=1.)\n",
    "    #precip_extreme=precip_extreme.where(precip_extreme>=threshold_new)\n",
    "    \n",
    "    #OCEAN\n",
    "    \n",
    "    ones=precip_extreme/precip_extreme\n",
    "    freq=ones.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5).where(ratio_all>=0.9).where(ratio_ocean>=0.9)/ratio_ocean\n",
    "    extreme_sum=precip_extreme.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5).where(ratio_all>=0.9).where(ratio_ocean>=0.9)/ratio_ocean\n",
    "    #freq=ones.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5)\n",
    "    #extreme_sum=precip_extreme.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5)\n",
    "    \n",
    "    weights=np.cos(np.deg2rad(extreme_sum.lat))\n",
    "    total_weighted=extreme_sum.weighted(weights)\n",
    "    freq_weighted=freq.weighted(weights)\n",
    "    weighted_1=precip_extreme.where(land_mask_interp<0.5).where(ratio_all>=0.9).where(ratio_ocean>=0.9).weighted(weights)\n",
    "    #weighted_1=precip_extreme.where(land_mask_interp<0.5).weighted(weights)\n",
    "    intensity=weighted_1.mean(skipna=True).values.tolist()\n",
    "    \n",
    "    if valid_area_ocean>=0.9:\n",
    "    #if 1==1:\n",
    "        total_list_ocean.append(total_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()*factor)\n",
    "        freq_list_ocean.append(freq_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()*factor)\n",
    "        intensity_list_ocean.append(intensity)\n",
    "    else:\n",
    "        total_list_ocean.append(np.nan)\n",
    "        freq_list_ocean.append(np.nan)\n",
    "        intensity_list_ocean.append(np.nan)\n",
    "\n",
    "    for j in range(12):\n",
    "        dates=[x for x in ones.time.values if pd.to_datetime(x).month==j+1]\n",
    "        precip_sel=precip.sel(time=dates)\n",
    "        defined1=xr.ones_like(precip_sel).sum(dim='time').where(land_mask_interp<0.5)\n",
    "        defined=xr.ones_like(precip_sel).where(precip_sel.round(2)>=0).sum(dim='time').where(land_mask_interp<0.5)\n",
    "        ratio=defined/defined1\n",
    "        valid_area=xr.ones_like(precip_sel).where(ratio>=0.9).fillna(0).where(land_mask_interp<0.5).weighted(weights).mean().values.tolist()\n",
    "    \n",
    "        field=precip_extreme.sel(time=dates)\n",
    "        extreme_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5).where(ratio_all>=0.9).where(ratio>=0.9)/ratio\n",
    "        #extreme_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5)\n",
    "        total_weighted=extreme_sum.weighted(weights)\n",
    "        total_mean=total_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()\n",
    "\n",
    "        field=ones.sel(time=dates)\n",
    "        ones_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5).where(ratio_all>=0.9).where(ratio>=0.9)/ratio\n",
    "        #ones_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp<0.5)\n",
    "        freq_weighted=ones_sum.weighted(weights)\n",
    "        freq_mean=freq_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()\n",
    "        \n",
    "        field=precip_extreme.sel(time=dates)\n",
    "        intensity_weighted=field.where(land_mask_interp<0.5).where(ratio_all>=0.9).where(ratio>=0.9).weighted(weights)\n",
    "        #intensity_weighted=field.where(land_mask_interp<0.5).weighted(weights)\n",
    "        intensity_mean=intensity_weighted.mean(skipna=True).values.tolist()\n",
    "        \n",
    "        if valid_area>=0.9:\n",
    "            total_ocean_monthly[j,i]=total_mean*factor\n",
    "            freq_ocean_monthly[j,i]=freq_mean*factor\n",
    "            intensity_ocean_monthly[j,i]=intensity_mean\n",
    "        else:\n",
    "            total_ocean_monthly[j,i]=np.nan\n",
    "            freq_ocean_monthly[j,i]=np.nan\n",
    "            intensity_ocean_monthly[j,i]=np.nan\n",
    "    \n",
    "    #LAND\n",
    "    \n",
    "    freq=ones.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5).where(ratio_all>=0.9).where(ratio_land>=0.9)/ratio_land\n",
    "    extreme_sum=precip_extreme.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5).where(ratio_all>=0.9).where(ratio_land>=0.9)/ratio_land\n",
    "    #freq=ones.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5)\n",
    "    #extreme_sum=precip_extreme.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5)\n",
    "    \n",
    "    weights=np.cos(np.deg2rad(extreme_sum.lat))\n",
    "    total_weighted=extreme_sum.weighted(weights)\n",
    "    freq_weighted=freq.weighted(weights)\n",
    "    weighted_1=precip_extreme.where(land_mask_interp>=0.5).where(ratio_all>=0.9).where(ratio_land>=0.9).weighted(weights)\n",
    "    #weighted_1=precip_extreme.where(land_mask_interp>=0.5).weighted(weights)\n",
    "    intensity=weighted_1.mean(skipna=True).values.tolist()\n",
    "    \n",
    "    if valid_area_land>=0.9:\n",
    "    #if 1==1:\n",
    "        print(total_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()*factor)\n",
    "        total_list_land.append(total_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()*factor)\n",
    "        freq_list_land.append(freq_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()*factor)\n",
    "        intensity_list_land.append(intensity)\n",
    "    else:\n",
    "        total_list_land.append(np.nan)\n",
    "        freq_list_land.append(np.nan)\n",
    "        intensity_list_land.append(np.nan)\n",
    "\n",
    "    for j in range(12):\n",
    "        dates=[x for x in ones.time.values if pd.to_datetime(x).month==j+1]\n",
    "        precip_sel=precip.sel(time=dates)\n",
    "        defined1=xr.ones_like(precip_sel).sum(dim='time').where(land_mask_interp>=0.5)\n",
    "        defined=xr.ones_like(precip_sel).where(precip_sel.round(2)>=0).sum(dim='time').where(land_mask_interp>=0.5)\n",
    "        ratio=defined/defined1\n",
    "        valid_area=xr.ones_like(precip_sel).where(ratio>=0.9).fillna(0).where(land_mask_interp>=0.5).weighted(weights).mean().values.tolist()\n",
    "        \n",
    "        field=precip_extreme.sel(time=dates)\n",
    "        extreme_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5).where(ratio_all>=0.9).where(ratio>=0.9)/ratio\n",
    "        #extreme_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5)\n",
    "        total_weighted=extreme_sum.weighted(weights)\n",
    "        total_mean=total_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()\n",
    "\n",
    "        field=ones.sel(time=dates)\n",
    "        ones_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5).where(ratio_all>=0.9).where(ratio>=0.9)/ratio\n",
    "        #ones_sum=field.sum(dim='time',skipna=True).fillna(0).where(land_mask_interp>=0.5)\n",
    "        freq_weighted=ones_sum.weighted(weights)\n",
    "        freq_mean=freq_weighted.mean(dim=('lat','lon'),skipna=True).values.tolist()\n",
    "\n",
    "        field=precip_extreme.sel(time=dates)\n",
    "        intensity_weighted=field.where(land_mask_interp>=0.5).where(ratio_all>=0.9).where(ratio>=0.9).weighted(weights)\n",
    "        #intensity_weighted=field.where(land_mask_interp>=0.5).weighted(weights)\n",
    "        intensity_mean=intensity_weighted.mean(skipna=True).values.tolist()\n",
    "        \n",
    "        if valid_area>=0.9:\n",
    "            total_land_monthly[j,i]=total_mean*factor\n",
    "            freq_land_monthly[j,i]=freq_mean*factor\n",
    "            intensity_land_monthly[j,i]=intensity_mean\n",
    "        else:\n",
    "            total_land_monthly[j,i]=np.nan\n",
    "            freq_land_monthly[j,i]=np.nan\n",
    "            intensity_land_monthly[j,i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dk=xr.Dataset()\n",
    "dk['total_list_gpcp3_ocean']=(('years'),total_list_ocean)\n",
    "dk['freq_list_gpcp3_ocean']=(('years'),freq_list_ocean)\n",
    "dk['intensity_list_gpcp3_ocean']=(('years'),intensity_list_ocean)\n",
    "\n",
    "dk['total_list_gpcp3_land']=(('years'),total_list_land)\n",
    "dk['freq_list_gpcp3_land']=(('years'),freq_list_land)\n",
    "dk['intensity_list_gpcp3_land']=(('years'),intensity_list_land)\n",
    "\n",
    "dk['total_gpcp3_ocean_monthly']=(('months','years'),total_ocean_monthly)\n",
    "dk['freq_gpcp3_ocean_monthly']=(('months','years'),freq_ocean_monthly)\n",
    "dk['intensity_gpcp3_ocean_monthly']=(('months','years'),intensity_ocean_monthly)\n",
    "\n",
    "dk['total_gpcp3_land_monthly']=(('months','years'),total_land_monthly)\n",
    "dk['freq_gpcp3_land_monthly']=(('months','years'),freq_land_monthly)\n",
    "dk['intensity_gpcp3_land_monthly']=(('months','years'),intensity_land_monthly)\n",
    "\n",
    "dk.coords['years']=np.arange(2001,2021,1)\n",
    "dk.coords['months']=np.arange(12)\n",
    "\n",
    "try:\n",
    "    os.remove(dir_data+'precip_datasets_compare_gpcp3_wet_6070_test.nc')\n",
    "except OSError:\n",
    "    pass\n",
    "dk.to_netcdf(dir_data+'precip_datasets_compare_gpcp3_wet_6070_test.nc',mode='w',format='NETCDF4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c928c8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
